!pip install transformers torch sentence-transformers faiss-cpu flask pyngrok

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from sentence_transformers import SentenceTransformer
from pyngrok import ngrok
import faiss
from flask import Flask, request, jsonify

model_name = "distilgpt2"
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')

knowledge_base = [
    {"title": "Document 1", "content": "Details about user registration..."},
    {"title": "Document 2", "content": "Details about shopping cart features..."},
]

def create_embeddings(documents):
    embeddings = []
    for doc in documents:
        embeddings.append(embedder.encode(doc["content"]))
    return embeddings

document_embeddings = create_embeddings(knowledge_base)

index = faiss.IndexFlatL2(768)
faiss_index = faiss.IndexIDMap(index)
faiss_index.add(np.array(document_embeddings))

app = Flask(__name__)

@app.route("/chat", methods=["POST"])
def chat():
    question = request.json["question"]
    question_embedding = embedder.encode([question])
    D, I = faiss_index.search(np.array(question_embedding), k=3)
    relevant_docs = [knowledge_base[i] for i in I[0]]
    
    inputs = tokenizer(question, return_tensors="pt")
    outputs = model.generate(**inputs)
    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return jsonify({"response": answer, "relevant_docs": relevant_docs})

ngrok.set_auth_token("YOUR_NGROK_TOKEN")
public_url = ngrok.connect(5000)
print("Public URL:", public_url)

if __name__ == "__main__":
    app.run(port=5000)
